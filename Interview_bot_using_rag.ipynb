{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koq0c34zHE9e",
    "outputId": "fd83aba6-63e4-4325-f7f0-012b10c5bb87"
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu rank_bm25 langchain_community torch transformers pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4rS4IChHNuN",
    "outputId": "6f6da6a3-88f5-4462-ec8e-d0e5a05e21a8"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHUS-DBlHfxf"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import nltk\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQT3olm-RJah",
    "outputId": "2eb6e1f9-0503-4b57-d1dd-6142a5cce8ec"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nq_vrJyCRMC-"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using pdfplumber.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the CV PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text or empty string if extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"No text extracted from PDF\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"  # Fallback to empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjHmpT35RPR0"
   },
   "outputs": [],
   "source": [
    "def create_knowledge_base(cv_text, job_des):\n",
    "    \"\"\"\n",
    "    Creates a knowledge base by splitting CV and job description into sentences.\n",
    "\n",
    "    Args:\n",
    "        cv_text (str): Text extracted from the CV.\n",
    "        job_des (str): Job description text.\n",
    "\n",
    "    Returns:\n",
    "        list: List of text chunks.\n",
    "    \"\"\"\n",
    "    knowledge_base = cv_text.split(\". \") + job_des.split(\". \")\n",
    "    knowledge_base = [chunk.strip() for chunk in knowledge_base if chunk.strip()]\n",
    "    return knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PFW6WRsRRVG"
   },
   "outputs": [],
   "source": [
    "def embed_knowledge_base(knowledge_base):\n",
    "    \"\"\"\n",
    "    Embeds the knowledge base using SentenceTransformer.\n",
    "\n",
    "    Args:\n",
    "        knowledge_base (list): List of text chunks.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Embeddings, knowledge base, and embedder instance.\n",
    "    \"\"\"\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = embedder.encode(knowledge_base, convert_to_numpy=True)\n",
    "    return embeddings, knowledge_base, embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmfTJDDFRTq2"
   },
   "outputs": [],
   "source": [
    "def build_faiss_index(embeddings):\n",
    "    \"\"\"\n",
    "    Builds a FAISS index for efficient similarity search.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): Embedded text chunks.\n",
    "\n",
    "    Returns:\n",
    "        faiss.IndexFlatL2: FAISS index.\n",
    "    \"\"\"\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJ55eHXWRV_E"
   },
   "outputs": [],
   "source": [
    "# Step 3: Retrieval Function\n",
    "def retrieve_relevant_chunks(query, index, knowledge_base, embedder, k=2):\n",
    "    \"\"\"\n",
    "    Retrieves the most relevant chunks based on the query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Query text (initial or candidate response).\n",
    "        index (faiss.IndexFlatL2): FAISS index.\n",
    "        knowledge_base (list): List of text chunks.\n",
    "        embedder (SentenceTransformer): Embedding model.\n",
    "        k (int): Number of chunks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: Retrieved relevant chunks.\n",
    "    \"\"\"\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    relevant_chunks = [knowledge_base[idx] for idx in indices[0]]\n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvne4Lq6RYW6"
   },
   "outputs": [],
   "source": [
    "# Step 4: Load Gemma-3-4b-it Model with Pipeline\n",
    "def load_gemma_model():\n",
    "    \"\"\"\n",
    "    Loads the Gemma-3-4b-it model and tokenizer, creating a text generation pipeline.\n",
    "\n",
    "    Returns:\n",
    "        pipeline: Text generation pipeline.\n",
    "    \"\"\"\n",
    "    model_name = \"google/gemma-3-4b-it\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(\"Tokenizer loaded\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "    print(\"Model loaded with device_map='auto'\")\n",
    "\n",
    "    llm_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=60,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "    return llm_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5yBEFjARa1g"
   },
   "outputs": [],
   "source": [
    "# Step 5: Dynamic Prompt and Question Generation\n",
    "def generate_dynamic_prompt(cv_chunks, job_chunks, keyword, prev_question=None, prev_response=None):\n",
    "    \"\"\"\n",
    "    Generates a dynamic prompt for the language model based on context and keyword.\n",
    "\n",
    "    Args:\n",
    "        cv_chunks (list): CV-related retrieved chunks.\n",
    "        job_chunks (list): Job description-related retrieved chunks.\n",
    "        keyword (str): Focus keyword for the question.\n",
    "        prev_question (str, optional): Previous question asked.\n",
    "        prev_response (str, optional): Candidate's previous response.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated prompt.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an AI interviewer generating questions based on a candidate’s CV and job description.\\n\"\n",
    "        \"CV Information:\\n\" + \"\\n\".join(cv_chunks) + \"\\n\"\n",
    "        \"Job Description Information:\\n\" + \"\\n\".join(job_chunks) + \"\\n\"\n",
    "    )\n",
    "    if prev_question and prev_response:\n",
    "        prompt += (\n",
    "            \"Previous Question: \" + prev_question + \"\\n\"\n",
    "            \"Candidate’s Response: \" + prev_response + \"\\n\"\n",
    "            \"Based on the CV, job description, and the candidate’s previous response, \"\n",
    "            \"generate a relevant follow-up question focusing on \" + keyword + \" to assess their fit for the role.\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt += (\n",
    "            \"Based on the CV and job description, generate an initial interview question \"\n",
    "            \"focusing on \" + keyword + \" to assess the candidate’s fit for the role.\\n\"\n",
    "        )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWic0uJJRdSi"
   },
   "outputs": [],
   "source": [
    "def generate_question(prompt, llm_pipeline):\n",
    "    \"\"\"\n",
    "    Generates a question using the language model pipeline.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Input prompt for the model.\n",
    "        llm_pipeline (pipeline): Text generation pipeline.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated question.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = llm_pipeline(prompt, return_full_text=False)[0][\"generated_text\"]\n",
    "        return output.strip() or \"Tell me about your experience.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating question: {e}\")\n",
    "        return \"Tell me about your experience.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcvVfRrZRfFK"
   },
   "outputs": [],
   "source": [
    "# Helper Function for Keyword Extraction\n",
    "def extract_keywords(text, top_n=10):\n",
    "    \"\"\"\n",
    "    Extracts the top N keywords (nouns) from the text using NLTK.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "        top_n (int): Number of keywords to extract.\n",
    "\n",
    "    Returns:\n",
    "        list: List of top keywords.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    nouns = [word for word, pos in tagged if pos.startswith('NN')]\n",
    "    freq_dist = nltk.FreqDist(nouns)\n",
    "    return [word for word, _ in freq_dist.most_common(top_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQbPXTJXRlHr"
   },
   "outputs": [],
   "source": [
    "# Main Application Logic with Conversational Flow\n",
    "def run_interview_bot(cv_path, job_des):\n",
    "    \"\"\"\n",
    "    Runs the AI interviewer bot, asking questions based on CV and job description.\n",
    "\n",
    "    Args:\n",
    "        cv_path (str): Path to the CV PDF file.\n",
    "        job_des (str): Job description text.\n",
    "    \"\"\"\n",
    "    # Extract CV text\n",
    "    cv_text = extract_text_from_pdf(cv_path)\n",
    "    if not cv_text:\n",
    "        print(\"Cannot proceed without CV text.\")\n",
    "        return\n",
    "\n",
    "    # Extract keywords from job description\n",
    "    job_keywords = extract_keywords(job_des, top_n=20)\n",
    "    if not job_keywords:\n",
    "        print(\"No keywords extracted from job description.\")\n",
    "        return\n",
    "\n",
    "    # Create and embed knowledge base\n",
    "    knowledge_base = create_knowledge_base(cv_text, job_des)\n",
    "    if not knowledge_base:\n",
    "        print(\"Knowledge base is empty. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    embeddings, knowledge_base, embedder = embed_knowledge_base(knowledge_base)\n",
    "    index = build_faiss_index(embeddings)\n",
    "    llm_pipeline = load_gemma_model()\n",
    "\n",
    "    # Initialize conversation variables\n",
    "    prev_question = None\n",
    "    prev_response = None\n",
    "\n",
    "    # Welcome message\n",
    "    print(\"Welcome to the AI Interviewer. I will ask you questions based on your CV and the job description.\")\n",
    "    print(\"Type 'exit' at any time to end the interview.\")\n",
    "\n",
    "    # Interview loop\n",
    "    while True:\n",
    "        # Set query based on whether it's the first question or a follow-up\n",
    "        if prev_response:\n",
    "            query = prev_response\n",
    "        else:\n",
    "            query = \"Assess candidate’s fit for the role\"\n",
    "\n",
    "        # Retrieve relevant chunks\n",
    "        retrieved_chunks = retrieve_relevant_chunks(query, index, knowledge_base, embedder)\n",
    "        chunk_text = \" \".join(retrieved_chunks).lower()\n",
    "\n",
    "        # Select a keyword: prefer one present in retrieved chunks\n",
    "        present_keywords = [kw for kw in job_keywords if kw in chunk_text]\n",
    "        if present_keywords:\n",
    "            keyword = random.choice(present_keywords)\n",
    "        else:\n",
    "            keyword = random.choice(job_keywords)\n",
    "\n",
    "        # Categorize retrieved chunks\n",
    "        cv_chunks = [chunk for chunk in retrieved_chunks if chunk in cv_text]\n",
    "        job_chunks = [chunk for chunk in retrieved_chunks if chunk in job_des]\n",
    "\n",
    "        # Generate and ask question\n",
    "        prompt = generate_dynamic_prompt(cv_chunks, job_chunks, keyword, prev_question, prev_response)\n",
    "        question = generate_question(prompt, llm_pipeline)\n",
    "\n",
    "        print(f\"Generated Question: {question}\")\n",
    "        prev_response = input(\"Candidate Response (or type 'exit' to stop): \")\n",
    "\n",
    "        # Check for exit condition\n",
    "        if prev_response.lower() == \"exit\":\n",
    "            print(\"Thank you for participating. The interview has ended.\")\n",
    "            break\n",
    "\n",
    "        prev_question = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uF9w8xiRDEx"
   },
   "outputs": [],
   "source": [
    "cv_path = \"/content/NavnishPandey_cv (1).pdf\"\n",
    "\n",
    "job_des = \"\"\"\n",
    "    Key Responsibilities\n",
    "Collect, clean, and preprocess data from diverse sources.\n",
    "Design, implement, and deploy machine learning models to solve real-world problems.\n",
    "Analyze large datasets to discover trends, patterns, and insights.\n",
    "Collaborate with cross-functional teams to define and solve business problems using data.\n",
    "Communicate findings through dashboards, reports, and presentations.\n",
    "Continuously monitor and improve the performance of deployed models.\n",
    "Required Qualifications\n",
    "Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, or a related field.\n",
    "Strong programming skills in Python or R.\n",
    "Hands-on experience with machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch).\n",
    "Proficiency in data manipulation using Pandas, NumPy, SQL.\n",
    "Familiarity with data visualization tools (e.g., Matplotlib, Seaborn, Tableau, Power BI).\n",
    "Experience in statistical modeling and A/B testing.\n",
    "Preferred Qualifications\n",
    "Experience working with cloud platforms (AWS, GCP, or Azure).\n",
    "Knowledge of NLP, time series, or computer vision is a plus.\n",
    "Exposure to MLOps tools and practices.\n",
    "Experience with big data tools like Spark, Hadoop is a bonus.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "70fb7e8878774e6abbb0ff4a12877f13",
      "eefe25cc13b44552aadace55db309f4b",
      "69ec00fe6c3b440eb08f836ffcc44511",
      "ded29be06a724ae78003e79fe7bd92e1",
      "49d1ef61b8cc4033b191f0ec566e0586",
      "6e52f70a724b46a5b16edaa0f2b6cee8",
      "7d4f0a9397a64be091d61f91403367e1",
      "03a72ae17eb34d60ab071be92a71c85e",
      "0c2d9bb1e4e945f9bda09527f2c58559",
      "e28d29f6bcaa45fc994e14a33de9b173",
      "cd8c4f8c629546d4877096737aa60c36",
      "b3b21a479fbe4602b5f87862cb8ad31b",
      "e72a1f450ab74b5cb8b3428be8696905",
      "aeb5386004f84a2b891d4eb3ddb1050f",
      "4db470c7c0a54c3bb757636ab12b503a",
      "b2a3084bac5d461ab6062d748ff34b9d",
      "76b3f33f41a84e2ba41d146d7892fcba",
      "005bc435ec9d4c1e99e6726d71c9e9aa",
      "b302f83acee546faafae34ef6f245b02",
      "f1727a6b945844f88fcf6bc288bc3139",
      "1eee4bbbcdbb4556a263ca0e12c15d11",
      "b7c407398a664721a8a30f1f931e11de",
      "38f3ba55bcaf49898616d381d2a358c9",
      "14db9a7e442240b39b385c9b9cbdc01b",
      "ab26e5c059d747858147b8885dfa86c2",
      "944473d60c4e488e8bfff4e32e15b8ab",
      "9dc9af83c3304d9b9e090a74bfa4efd1",
      "19af3fa6c07f4f2a8406d4e0a84140b5",
      "3a2d4381bdb442c48a73b13f178e9bbb",
      "8ca2a44badf14e1eaf260ad053d1eff2",
      "72e75a0d94bc49a9ab7c27fce44361d2",
      "b085fc3eb69a4277bdb9d423225b5f6a",
      "78ead98b141b4682bbaef581abf4b12c",
      "e700610e40df431c97ecc44c254e6d35",
      "94b466e73db148a38c1b1d5dbd6dbbc6",
      "c9ae28fc1b7445cfa05bb0a009724d31",
      "4c392a5845744346afa6fab690d94532",
      "3ed6f272da944206a51c0de483a76aa5",
      "b950d6ed97af4f249812858bec56c9ca",
      "e300ad06c5a5491d909202d556966dc3",
      "4cc08fdeb23d46fabf24def3a22e11ca",
      "9283d0df782f42bf8a3be104a960237e",
      "80ff153a0738464eb0f0cb212eccf6ec",
      "58d270d6f49843c8aa8720824fd20599",
      "3ab6f619bddd4275bc5b1663fbaff6cf",
      "43272cf51ccb406fb71cfd2778e630b3",
      "dce9f51724274dd5bcd868193c02c555",
      "82052d0f6754409ca1affce12fba8687",
      "c4bef52ef7c94c32bbcfdb10233bca78",
      "6411d68d844f438fbe8a7eb9aee0f4b2",
      "9318df3958994ffdadf3eb884b4d2487",
      "541e30d8f0424f91999c63a9ff60b105",
      "88a8b548490f4a75a3af1cdffb6282d3",
      "353135df8d0c49158e9705262027c698",
      "c8b0675aa0a84bde85943542bc28fa3b",
      "ca3070552a6344ffb9cb33c9dedab186",
      "60c9e742a1c746259c6a00a8a0d7042d",
      "87033c65068649688121a38d32495936",
      "fe587262f4844ca1ad06b313473cd039",
      "357ad0b84e9a4b5b95f6b7a1bcc23906",
      "403207670311405799817930eb326ca9",
      "b6a62997880b45fe98fc530910e355ea",
      "a282d4e7fe6b4f7a8f3a1994ceb96a37",
      "327d7638bf59454a9ae029f6b01d022e",
      "62074cd8a5d446c2b618fe1c7b25a48e",
      "652e2866041a41c2ab6c9123c32a1a8d",
      "ed91a1c274ff40fb98d578b8fd24d0e8",
      "0a0304f811b34474a90daed67f9c29d4",
      "8de4d3467a924d26acc0665bd58ba373",
      "cb14ee3a4728438bba2923db2f034c98",
      "78e64e03a3bc4f538860b13878012ff4",
      "75a2f09e87e24affb6022efcdfd3f1b5",
      "a9a521accb69425a9c0ad2820aec509a",
      "925539343acb4cdea71bf532ba4453d2",
      "301dd759bef04112a745e3a0fccb83fe",
      "3db83ade36df4b3f9019be336cd2523d",
      "24f792c6bcd9452cb8b51cb98fd7e132",
      "718af58f8328432da7ae84d88d9a76d7",
      "166132757ce54acbaa7028c43a40b6a1",
      "8dcb49155eb143e89ebbb7931343d51b",
      "b38564353a06494894d3b03184200b58",
      "8308cff1908d456a84d9fa0b1effb843",
      "d9cae3a3d30e4cc194caa824761831d8",
      "b61d5cf15356467b80dcbd0e408081e9",
      "816362be36a14dd394a4e46de07b3de6",
      "d2d9fe3691c34050b6c5b0b2e34193a6",
      "f185e6df5468405e9de0bbcc9f637fb5",
      "d4ef73bb80424f4dac04cc71e4935655",
      "89a5d0b697504082b0548961f738c25d",
      "36e6d763774544f997e9a2a42087f8cd",
      "e800cb721dbf40bc9f944b04f91978f3",
      "ada616678c464c21b3f37fb20c440bdf",
      "aa284e599ce349bfb8a88ce4b4d0d292",
      "6d86f1c0fcbe4b2db0ebc6e1409e9f30",
      "845bcc90c9af49a5837e6c9e4873b6ba",
      "d546ff0ed81e4d11a24c5807a8985f42",
      "c013a89561144047bd4ff265a277f599",
      "e6daadae431b431db2869977330e6feb",
      "297a0f00ae0243f0901a51c5e8aff623",
      "edf8f1e7052d40449ff730331aabdb0b",
      "733524b0d4a248aeb4d08ec14fa799db",
      "62be4374ab344d1dae94442629efdf81",
      "a18fa083bc7c4e7e901c84b3961d8395",
      "9467a252d1b242f6afbff908b14df0bc",
      "6ab581a56dec45b2ac002010261d2cb0",
      "224329f02a564fd6a8d33948cc2db09e",
      "308963552a054db19650b966d224ce49",
      "b90bb47712d14578afe460049eb05040",
      "d8c94a59eb664ab198a95336c1c503d4",
      "835be20bc98f46a48dd7a187391c958a",
      "899720ce87b342c4a38a4daab39bdeff",
      "85b975ff142941a38272d250c7c1d25b",
      "b27dc7e731e743f598704bd45420fc06",
      "5934068cb4de4fa590528eab8a086c62",
      "c8839754c42042ddbaae445cae0eef77",
      "66f26743c11d43bdb537b3bcfa0cb48d",
      "5cb3861d688a4522af0f03c5c4eb6582",
      "b7d74c418b044749ac7cdfc8dc52736e",
      "0163b8f9c2cf408a81a94d723e4ece4b",
      "cb651ea5e7e1420884a3b4832f79b4a5",
      "bd6fedec17654597aa48723c985e05d1",
      "71f1865f0cbf482b96a7fba9fcd0378e",
      "90a0e90c79b944f7b9a241ae8f17887b",
      "fdab9fd56a374f0cb6451259f9b9cf1f",
      "066fcaaaecb349f59d8e2684bae481ba",
      "e523069caecc44f881f9d819be0718ae",
      "ced8a9587a904fb7aa26539c2056f10f",
      "7690e6c299404f6499eddaf849f95ce0",
      "cce84d31be5743f5b295de47b19eb2c1",
      "4f6ca95e79664f119d463d28930299da",
      "7f9b7ad54c2b46578ce36b1fc459c372",
      "dacbc3b20ba9449baf32bfb0a2809e12",
      "72553e31737e4ee5bb27c4e4acf06b28",
      "6409751665194763a3701d0501e47780",
      "f6ff323c0f274844a551dcea83be8034",
      "4404b4c95ec94e25ab2b9b4fd04186b5",
      "6b5143b1fada41b78359a7f65f00f379",
      "3c81550009814d1591264c9a3c4607f7",
      "96116b098fdd4f828e7c60d33e09b09c",
      "bf212ee9ff2b4473b5f1f28180d10309",
      "b55f0f21da0d4c61bca44800fb9505fc",
      "5401c8f73d354300a0d73054128efeda",
      "221e19de79414bd09ae5f601a2399c9e",
      "435ae77272af4cc0ac64fddcc3c217f8",
      "7cdfe46135584e63b457162b18fae0f7",
      "17407c2b33134bf08534438e2ee527ff",
      "ba54d154e5e4409298b8482ad70866f6",
      "ce796371b6914c699a4cc296a8f0d9cc",
      "957d3e3e2f2c45488214a1d72db0197e",
      "6851b8c8461a4e29a15d496b980ffaf7",
      "8ed9ac527d52452fbd5f6c6626ccc94e",
      "5587b2b483a1486782424e29fef8abb9",
      "3a8aebd12a8f44618637d86395da4960",
      "e9324bca89514037b84044e43ee12c31",
      "4c066eab730a4f73800b74c8f0a0464b",
      "d3da2e5f873c42cd91bebcea79d47750",
      "93d2ee45b5e0436d9a3fa7c1d1e5f2ac",
      "793e28d0f83648ab96492a0f75581c8f",
      "a0ede46d62594a0392d0f7b0df1b9c6f",
      "31abce4145094934984e48450cf0b94d",
      "83b322ce9e534fda91f15e0872dbf315",
      "14d390e5a212452b9ef949f821ff40b8",
      "9a7c103d66ce4182bda27f72d51c64f0",
      "cb2cd7ac48134a789c30b786a2f86583",
      "be84d88106df436e811c936912d26a8f",
      "6b8f1cd96500495b914ce71adfdca387",
      "0d58d7fe31b54896a9df7ebeb2e80a28",
      "3cd7cc0bd3e14309a4aa9bc50892df25",
      "0ce6972a60e3424baf2a374df41d4225",
      "208e0da448044bc7802e220385e6c4bd",
      "b6d50d4dbb2a46bdb4997e6b239db70e",
      "5c12444c306341d385a4c1aa2af592cd",
      "d17d057a3d0d429cb5d77686f8aa64ea",
      "1ddf01db8503418e81ebbba78a85aeee",
      "fea9f8b1692b43f697c1cc328c42452c",
      "14cd40cde6ce466cb6a28c0210593612",
      "e7fcef288a734adf9bca292f2498ceae",
      "6d84d90ab25c4026b934d3e157d211df",
      "bb174778ecac4a5e8b4e8e98158b2e0f",
      "f8c44aefef3c4c90b562e890e8e1bf8e",
      "8aea6b2026ca44c0860e4b4771fd2a46",
      "55f0b989e1cb412ab211eec58e3a7fed",
      "d6401454526843108ded4f476080acbe",
      "808dbd2d2e394f3c915b813703137f15",
      "706939d2f1cd4767bb705387eaca4680",
      "c57cd5b13e2f44b69f95c422bae8971c",
      "e328a5a7ac264739a30fb33489acb7fe",
      "8f2ad6597fa64db0aed370d5516ce7a6",
      "10342091f77c47cba0c9b9c98f803143",
      "c6056decbb124e20987b55db9bc7c929",
      "f6070f886ec349fdab15fcbc8d94dddf",
      "44a22ce8afd04fd4bac01fbdadae0238",
      "73177ce689434203ab60d9651fafdd96",
      "f38cb5cd85a343f4a19b2fd091094413",
      "a7e9d4ca9c6645a1b20cab2d9c909db4",
      "02d0d975bd504598b406590db0ca094f",
      "fa80c2c346ee4cde98ebfdbd5b048191",
      "5948eece33db4b1a8edbb6a575a5b1e5",
      "beacd4e4443e479bb70719b9ae078e39",
      "8292d51c1a9a4fefbf05880b178ed51b",
      "a6a4316b2d284353aedece9ac416b978",
      "1b9b549265224fe5bc136db9676b50af",
      "2ec1c2f54ff64d90937e09c51eb0d966",
      "8e36c2d164d046f9ad3fdd767017e5b2",
      "23261d24ffc34dd291792c2a65cb098d",
      "fe15b19018d94458ba55ad89fd6e76a6",
      "efcb1c9aaf0c437f861704b18dc1afd1",
      "acc7df3fc7494353bad86017ebe16e30",
      "063b19dcc2314461b8d6275128fd1022",
      "3a2018a63170430483b5e1a1b98aa2d8",
      "269713d5221c481a85ed3388b1eb48a5",
      "a79070ea60484656b36056f59088993f",
      "a462adefd8a349d4b59756c67d0a2b23",
      "be04d0c4d92149138741d22e9418dc85",
      "924067af5c31407e9dd3d0c90ab49546",
      "6e40438f9b7d4b29866644ab02eaa379",
      "62be2d449c9c4eb290f57e3d0ef6e618",
      "42934d0fbcb7456ca52e2a98fb37677d",
      "93bd20bd8dd74fe7949f3facb6e51a4c",
      "e2a43c39f4f8498a89a2e0f3f8edb9b8",
      "08bfeaa2ad604a30adf1276eeafaca08",
      "25cdd783f38d4cc4a776ca46a60e25fe",
      "9c143c39ebb44d2e99feab5b3ff551fd",
      "918ae79b83a6479098975697cb86f32c",
      "9e849bfe10d84ca99c4e4e9afcf4b6f3",
      "8d83f50fdfa34daca69ecf6228664c02",
      "25c39836e0ed41d2ad853a9b26fdc715",
      "8b0b54951a1744ef9cd866accc3274df",
      "72c09725485d41d7983a86cd87ebd6da",
      "329ac433eae644018b36cfd15a5addb8",
      "092fb667dc464e479ba7e8a687ea651b",
      "2cf68d2055284b67ba050ebfd2925666",
      "81bb0ea66e1a4bef8eaf95db8dbcb673",
      "ad8c9572b6944e1b98bec79cfc8bf310",
      "7ef64641f6504d39a8511d2926f38e7a",
      "6648dbfece5b4e1eb59edb308ec40119",
      "8f040adbe3db44b690e6caefc739e991",
      "1323c1fe83af4370869618972e91bf83",
      "533a4446013b4334af9008bedc7bf5eb",
      "309b54d7c4374cba902053cc1607af1e",
      "9face58da21c4cd0a0be976031428c69",
      "25f6cb0d48454b65bf372801428375b4",
      "6219daa879b540ad926b1277ad4659e2",
      "58b84b45651f44ea855cbaad69c00093",
      "4b330cdfb052485d9619808bb6f87809",
      "010c74e5ab7745de952bfa9a654cd4a1",
      "1b425979273648458e4b1320c41283e9",
      "615ad90047b8472db649a8bbce80655f",
      "70c67952c4cf4b20abe999542682f59a",
      "089c2099ec664716ae5233e277150bed",
      "b57fadd512a9490a8bab5c504ae5176a",
      "f10850be3184494698b6f004e616aaaf",
      "c89800e1d09e4460b6ad81c63576ea90"
     ]
    },
    "id": "QOumTCyKTODy",
    "outputId": "5f0a4d5c-0747-4214-9d76-7bebb2472456"
   },
   "outputs": [],
   "source": [
    "run_interview_bot(cv_path, job_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DF0aBGrTfP_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
